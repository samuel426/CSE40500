# scripts/train_bilstm.py

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from common.dataset import StockDataset

# =======================
# 1. ÏÑ§Ï†ï
# =======================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
INPUT_SIZE = 5
SEQ_LEN = 60
BATCH_SIZE = 32
EPOCHS = 30
LR = 0.001

DATA_ROOT = "./data"
MODEL_ROOT = "./models/BiLSTM"

TICKERS = ["KOSPI", "Apple", "NASDAQ", "Tesla", "Samsung"]

# =======================
# 2. Bi-LSTM Î™®Îç∏ Ï†ïÏùò
# =======================
class BiLSTMModel(nn.Module):
    def __init__(self):
        super(BiLSTMModel, self).__init__()
        self.lstm = nn.LSTM(INPUT_SIZE, 64, num_layers=2, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(64 * 2, 1)  # ÏñëÎ∞©Ìñ•Ïù¥ÎØÄÎ°ú hidden_size x2

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]
        out = self.fc(out)
        return out

# =======================
# 3. ÌïôÏäµ Ìï®Ïàò
# =======================
def train(model, train_loader, val_loader, save_path):
    model = model.to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    best_val_loss = np.inf

    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0.0

        for inputs, targets in train_loader:
            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_train_loss = total_loss / len(train_loader)

        # Validation
        model.eval()
        total_val_loss = 0.0
        with torch.no_grad():
            for inputs, targets in val_loader:
                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                total_val_loss += loss.item()

        avg_val_loss = total_val_loss / len(val_loader)
        print(f"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {avg_train_loss:.6f}  Val Loss: {avg_val_loss:.6f}")

        # ÏµúÏ†Å Î™®Îç∏ Ï†ÄÏû•
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), save_path)
            print(f"‚úÖ Best model saved to {save_path}")

# =======================
# 4. Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è ÌïôÏäµ Ïã§Ìñâ
# =======================
def main():
    os.makedirs(MODEL_ROOT, exist_ok=True)

    for ticker in TICKERS:
        print(f"=== Training {ticker} ===")
        data_path = os.path.join(DATA_ROOT, ticker, "ohlcv.csv")
        df = pd.read_csv(
            data_path,
            skiprows=3,  # (3Ï§Ñ Î¨¥Ïãú: Ticker + Date + Í≥µÎ∞± Ï§Ñ)
            header=None,  # Ìó§Îçî ÏóÜÎã§Í≥† ÏÑ†Ïñ∏
            names=["Open", "High", "Low", "Close", "Volume"],  # Ïó¥ Ïù¥Î¶Ñ ÏßÅÏ†ë ÏßÄÏ†ï
            index_col=None
        )


        total_len = len(df)
        split1 = int(total_len * 0.3)
        split2 = int(total_len * 0.6)

        df_train = df.iloc[:split1]
        df_val = df.iloc[split1:split2]

        train_dataset = StockDataset(df_train)
        val_dataset = StockDataset(df_val)

        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

        model = BiLSTMModel()

        save_path = os.path.join(MODEL_ROOT, f"{ticker}.pth")
        train(model, train_loader, val_loader, save_path)

    print("üéØ Î™®Îì† Bi-LSTM Î™®Îç∏ ÌïôÏäµ ÏôÑÎ£å.")

# =======================
# 5. ÏãúÏûë
# =======================
if __name__ == "__main__":
    main()
