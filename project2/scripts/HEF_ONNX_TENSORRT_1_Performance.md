## NPU vs ONNX Runtime (GPU) vs TensorRT (GPU) 성능 비교

아래는 `GRU_Apple` 모델을 기준으로 NPU, ONNX Runtime(GPU), TensorRT(GPU)의 성능을 비교한 결과입니다.

---

### 1. Latency (지연 시간, 단위: ms)

| 구분     | NPU (GRU_Apple) | ONNX (GRU_Apple) | TensorRT (GRU_Apple) | TensorRT 우위 (NPU 대비) | TensorRT 우위 (ONNX 대비) |
|----------|-----------------|------------------|----------------------|--------------------------|---------------------------|
| **mean** | 1.326           | 0.194            | 0.071                | **약 18.7배 빠름**       | **약 2.7배 빠름**         |
| **median**| 1.319           | 0.185            | 0.071                | **약 18.6배 빠름**       | **약 2.6배 빠름**         |
| **min**  | 1.278           | 0.178            | 0.065                | **약 19.7배 빠름**       | **약 2.7배 빠름**         |
| **max**  | 1.417           | 0.496            | 0.148                | **약 9.6배 빠름**        | **약 3.4배 빠름**         |
| **p95**  | 1.397           | 0.219            | 0.073                | **약 19.1배 빠름**       | **약 3.0배 빠름**         |
| **p99**  | 1.413           | 0.319            | 0.077                | **약 18.3배 빠름**       | **약 4.1배 빠름**         |

*   **분석:**
    *   TensorRT가 세 플랫폼 중 가장 낮은 지연 시간을 보여주며, NPU 대비 약 18~19배, ONNX Runtime 대비 약 2.6~4.1배 빠른 속도를 제공합니다.
    *   ONNX Runtime도 NPU에 비해서는 약 6~7배 빠른 성능을 보입니다.
    *   모든 지표에서 TensorRT > ONNX Runtime > NPU 순으로 빠른 지연 시간을 기록했습니다.

---

### 2. Throughput (초당 처리량, 단위: FPS)

| 구분             | NPU (GRU_Apple) | ONNX (GRU_Apple) | TensorRT (GRU_Apple) | TensorRT 우위 (NPU 대비) | TensorRT 우위 (ONNX 대비) |
|------------------|-----------------|------------------|----------------------|--------------------------|---------------------------|
| **throughput_fps** | 764.05          | 5148.22          | 14035.85             | **약 18.4배 높음**       | **약 2.7배 높음**         |

*   **분석:**
    *   Throughput 역시 TensorRT가 가장 높아, NPU 대비 약 18.4배, ONNX Runtime 대비 약 2.7배 더 많은 데이터를 초당 처리할 수 있습니다.
    *   ONNX Runtime은 NPU 대비 약 6.7배 높은 처리량을 보입니다.

---

### 3. RMSE (Root Mean Squared Error, 예측 오차)

| 구분   | NPU (GRU_Apple) | ONNX (GRU_Apple) | TensorRT (GRU_Apple) | 비고 (낮을수록 좋음) |
|--------|-----------------|------------------|----------------------|----------------------|
| **rmse** | 54.90           | 42.14            | 42.24                | ONNX, TensorRT 우수  |

*   **분석:**
    *   RMSE 값은 ONNX Runtime과 TensorRT가 NPU보다 낮게 나타나, GPU 기반 실행 시 예측 정확도가 더 높음을 알 수 있습니다.
    *   ONNX Runtime과 TensorRT 간의 RMSE 차이는 미미합니다.

---

### 4. Utilization (평균 모델 사용률)

| 구분                    | NPU (GRU_Apple) | ONNX (GRU_Apple) | TensorRT (GRU_Apple) | 비고                                                                 |
|-------------------------|-----------------|------------------|----------------------|----------------------------------------------------------------------|
| **avg_model_utilization** | 14.10 %         | 0.0 %            | 0.0 %                | NPU 사용률이 상대적으로 높음. GPU는 매우 낮은 사용률로 높은 성능 달성. |
| **utilization_samples**   | 6               | 8                | 8                    |                                                                      |
| **utilization_values**    | `[75.0,...1.9]` | `[0,0,0,0,0,0,0,0]`| `[0,0,0,0,0,0,0,0]`  | NPU는 변동, GPU는 0%로 일정.                                         |

*   **분석:**
    *   NPU는 평균 14.1%의 사용률을 보인 반면, ONNX Runtime과 TensorRT는 측정된 `avg_model_utilization`이 0%로 기록되었습니다.
    *   이는 GPU의 처리 성능이 매우 뛰어나서 해당 모델 추론에 거의 부하가 걸리지 않았음을 의미하거나, 측정 간격(ONNX/TensorRT: 25ms) 동안의 순간적인 사용률이 0에 가까웠을 수 있음을 시사합니다.
    *   NPU는 특정 시점에 75%까지 사용률이 올라가는 반면, GPU는 매우 낮은 리소스 점유로도 훨씬 높은 성능을 달성했습니다.

---

### 5. Power Consumption (평균 전력 소비, ONNX Runtime만 제공)

| 구분              | NPU (GRU_Apple) | ONNX (GRU_Apple) | TensorRT (GRU_Apple) |
|-------------------|-----------------|------------------|----------------------|
| **avg_power_watts** | N/A             | 40.47 W          | N/A                  |

*   **분석:**
    *   ONNX Runtime 실행 시 GPU의 평균 전력 소비는 약 40.47W로 측정되었습니다. NPU 및 TensorRT 스크립트에서는 해당 지표가 수집되지 않았습니다.

---

### 종합 결론

`GRU_Apple` 모델을 기준으로 세 플랫폼을 비교한 결과, **TensorRT(GPU)가 Latency, Throughput 측면에서 가장 우수한 성능**을 보였습니다. ONNX Runtime(GPU) 역시 NPU에 비해 월등히 높은 성능을 제공했습니다. RMSE(예측 정확도)는 GPU 기반 실행(ONNX, TensorRT)이 NPU보다 더 좋았습니다.

*   **성능 순서 (빠른 순):** TensorRT > ONNX Runtime > NPU
*   **자원 활용:** GPU(ONNX, TensorRT)는 매우 낮은 사용률로도 NPU보다 훨씬 높은 성능을 달성하여, 해당 모델 및 작업에 대해 GPU의 연산 효율성이 매우 높음을 알 수 있습니다.

NPU는 상대적으로 높은 사용률을 보이면서도 GPU 플랫폼에 비해 낮은 성능을 기록했습니다. 이는 특정 작업에 대한 하드웨어 가속기의 최적화 수준 및 아키텍처 차이에서 비롯될 수 있습니다.